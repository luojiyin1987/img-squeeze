use crate::error::{CompressionError, Result};
use crate::processing::{CompressionOptions, process_image_pipeline};
use crate::constants::{
    MAX_BATCH_MEMORY_MB, MAX_BATCH_FILES, MIN_AVAILABLE_MEMORY_MB,
    LARGE_IMAGE_THRESHOLD_MB, MAX_CONCURRENT_LARGE_IMAGES
};
use glob::glob;
use indicatif::{ProgressBar, ProgressStyle};
use rayon::prelude::*;
use std::fs;
use std::path::{Path, PathBuf};
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::Instant;
use walkdir::WalkDir;

/// Estimates memory usage for an image file without loading it into memory.
/// 
/// # Arguments
/// * `file_path` - Path to the image file
/// 
/// # Returns
/// * `Ok(memory_mb)` - Estimated memory usage in MB
/// * `Err(CompressionError)` - If file metadata cannot be read
fn estimate_image_memory_usage(file_path: &Path) -> Result<f64> {
    let metadata = fs::metadata(file_path)?;
    let file_size_mb = metadata.len() as f64 / (1024.0 * 1024.0);
    
    // Conservative estimate: uncompressed image memory usage is typically 3-4x file size
    // for compressed formats like JPEG, and 1-1.5x for uncompressed formats like BMP
    let multiplier = match file_path.extension().and_then(|s| s.to_str()) {
        Some(ext) => match ext.to_lowercase().as_str() {
            "jpg" | "jpeg" => 4.0,  // JPEG compression ratio is typically high
            "png" => 3.0,           // PNG has good compression
            "webp" => 3.5,          // WebP has good compression
            "bmp" | "tiff" => 1.2,  // Usually uncompressed or lightly compressed
            "gif" => 2.0,           // GIF has moderate compression
            _ => 3.0,               // Default conservative estimate
        },
        None => 3.0,
    };
    
    Ok(file_size_mb * multiplier)
}

/// Validates batch memory requirements before processing.
/// 
/// # Arguments
/// * `image_files` - List of image file paths to process
/// 
/// # Returns
/// * `Ok((total_memory_mb, large_image_count))` - Estimated memory usage and count of large images
/// * `Err(CompressionError)` - If memory limits would be exceeded
fn validate_batch_memory_limits(image_files: &[PathBuf]) -> Result<(f64, usize)> {
    // Check file count limit
    if image_files.len() > MAX_BATCH_FILES {
        return Err(CompressionError::BatchFileLimitExceeded(
            image_files.len(),
            MAX_BATCH_FILES,
        ));
    }
    
    let mut total_memory_mb = 0.0;
    let mut large_image_count = 0;
    
    // Estimate memory usage for each file
    for file_path in image_files {
        let memory_estimate = estimate_image_memory_usage(file_path)?;
        total_memory_mb += memory_estimate;
        
        if memory_estimate > LARGE_IMAGE_THRESHOLD_MB {
            large_image_count += 1;
        }
    }
    
    // Check total memory limit
    let total_memory_mb_u64 = total_memory_mb.ceil() as u64;
    if total_memory_mb_u64 > MAX_BATCH_MEMORY_MB {
        return Err(CompressionError::BatchMemoryLimitExceeded(
            total_memory_mb_u64,
            MAX_BATCH_MEMORY_MB,
        ));
    }
    
    // Check if we have enough available memory (simplified check)
    // In a real implementation, this could query actual system memory
    let required_with_buffer = total_memory_mb_u64 + MIN_AVAILABLE_MEMORY_MB;
    if required_with_buffer > MAX_BATCH_MEMORY_MB + MIN_AVAILABLE_MEMORY_MB {
        return Err(CompressionError::InsufficientMemory(
            total_memory_mb_u64,
            MAX_BATCH_MEMORY_MB,
        ));
    }
    
    Ok((total_memory_mb, large_image_count))
}

pub fn batch_compress_images(
    input: String,
    output: PathBuf,
    options: CompressionOptions,
    recursive: bool,
) -> Result<()> {
    println!("ğŸš€ Starting batch compression...");
    println!("ğŸ“ Input: {}", input);
    println!("ğŸ“ Output: {:?}", output);

    let start_time = Instant::now();

    // æ”¶é›†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    let image_files = collect_image_files(&input, recursive)?;
    let total_files = image_files.len();

    if total_files == 0 {
        println!("âš ï¸  No image files found in the input path");
        return Ok(());
    }

    println!("ğŸ“Š Found {} image files to process", total_files);

    // Security: Validate batch memory requirements before processing
    println!("ğŸ” Validating batch memory requirements...");
    let (estimated_memory_mb, large_image_count) = validate_batch_memory_limits(&image_files)?;
    
    println!("ğŸ“Š Batch validation complete:");
    println!("  ğŸ“ Total files: {}", total_files);
    println!("  ğŸ’¾ Estimated memory usage: {:.1} MB", estimated_memory_mb);
    println!("  ğŸ“ Large images (>{}MB): {}", LARGE_IMAGE_THRESHOLD_MB, large_image_count);
    
    // Adjust parallelism based on large image count to prevent memory exhaustion
    let max_parallelism = if large_image_count > MAX_CONCURRENT_LARGE_IMAGES {
        MAX_CONCURRENT_LARGE_IMAGES
    } else {
        rayon::current_num_threads().min(total_files)
    };
    
    println!("âš™ï¸  Using {} parallel threads for processing", max_parallelism);

    // åˆ›å»ºè¾“å‡ºç›®å½•
    fs::create_dir_all(&output)
        .map_err(|_| CompressionError::DirectoryCreationFailed(output.clone()))?;

    // è®¾ç½®è¿›åº¦æ¡
    let main_progress = ProgressBar::new(total_files as u64);
    main_progress.set_style(ProgressStyle::default_bar());

    let processed_count = Arc::new(AtomicUsize::new(0));
    let total_size_before = Arc::new(AtomicUsize::new(0));
    let total_size_after = Arc::new(AtomicUsize::new(0));

    // Security: Use limited parallelism based on memory requirements
    let results: Vec<Result<()>> = if large_image_count > MAX_CONCURRENT_LARGE_IMAGES {
        // For batches with many large images, use chunked processing to limit memory usage
        let chunk_size = MAX_CONCURRENT_LARGE_IMAGES.max(1);
        image_files
            .chunks(chunk_size)
            .flat_map(|chunk| {
                chunk
                    .into_par_iter()
                    .map(|input_path| {
                        let processed_count = processed_count.clone();
                        let total_size_before = total_size_before.clone();
                        let total_size_after = total_size_after.clone();

                        match process_single_image(&input_path, &output, &options) {
                            Ok((before_size, after_size)) => {
                                total_size_before.fetch_add(before_size, Ordering::Relaxed);
                                total_size_after.fetch_add(after_size, Ordering::Relaxed);
                                processed_count.fetch_add(1, Ordering::Relaxed);
                                Ok(())
                            }
                            Err(e) => {
                                eprintln!("âŒ Failed to process {:?}: {}", input_path, e);
                                Err(e)
                            }
                        }
                    })
                    .collect::<Vec<_>>()
            })
            .collect()
    } else {
        // Standard parallel processing for smaller batches
        image_files
            .into_par_iter()
            .map(|input_path| {
                let processed_count = processed_count.clone();
                let total_size_before = total_size_before.clone();
                let total_size_after = total_size_after.clone();

                match process_single_image(&input_path, &output, &options) {
                    Ok((before_size, after_size)) => {
                        total_size_before.fetch_add(before_size, Ordering::Relaxed);
                        total_size_after.fetch_add(after_size, Ordering::Relaxed);
                        processed_count.fetch_add(1, Ordering::Relaxed);
                        Ok(())
                    }
                    Err(e) => {
                        eprintln!("âŒ Failed to process {:?}: {}", input_path, e);
                        Err(e)
                    }
                }
            })
            .collect()
    };

    main_progress.finish_with_message("âœ… Batch compression complete");

    // è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    let total_before = total_size_before.load(Ordering::Relaxed);
    let total_after = total_size_after.load(Ordering::Relaxed);
    let compression_ratio = if total_before > 0 {
        ((total_before as f64 - total_after as f64) / total_before as f64) * 100.0
    } else {
        0.0
    };

    let elapsed_time = start_time.elapsed();

    println!("\nğŸ“Š Batch Compression Summary:");
    println!(
        "  ğŸ“ Total files processed: {}",
        processed_count.load(Ordering::Relaxed)
    );
    println!("  ğŸ“Š Total original size: {} bytes", total_before);
    println!("  ğŸ“Š Total compressed size: {} bytes", total_after);
    println!("  ğŸ¯ Overall compression ratio: {:.1}%", compression_ratio);
    println!("  â±ï¸  Total time: {:?}", elapsed_time);
    println!(
        "  âš¡ Average speed: {:.2} files/second",
        processed_count.load(Ordering::Relaxed) as f64 / elapsed_time.as_secs_f64()
    );

    // æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„æ–‡ä»¶
    let failed_count = results.iter().filter(|r| r.is_err()).count();
    if failed_count > 0 {
        println!("  âš ï¸  Failed files: {}", failed_count);
    }

    Ok(())
}

pub fn collect_image_files(input: &str, recursive: bool) -> Result<Vec<PathBuf>> {
    let mut image_files = Vec::new();

    // Security: Validate and canonicalize input path to prevent directory traversal
    let input_path = Path::new(input);
    let canonical_input = if input_path.exists() {
        input_path.canonicalize()
            .map_err(|_| CompressionError::NoImageFilesFound(input.to_string()))?
    } else {
        // For glob patterns, we'll validate each result individually
        input_path.to_path_buf()
    };

    if canonical_input.exists() && canonical_input.is_file() {
        // å•ä¸ªæ–‡ä»¶
        image_files.push(canonical_input);
    } else if canonical_input.exists() && canonical_input.is_dir() {
        // ç›®å½•å¤„ç†
        let walker = if recursive {
            WalkDir::new(&canonical_input).into_iter()
        } else {
            WalkDir::new(&canonical_input).max_depth(1).into_iter()
        };

        for entry in walker.filter_entry(|e| !e.file_name().to_string_lossy().starts_with('.')) {
            let entry = entry?;
            let path = entry.path();

            if path.is_file() && is_image_file(path) {
                // Security: Canonicalize each file path
                if let Ok(canonical_path) = path.canonicalize() {
                    image_files.push(canonical_path);
                }
            }
        }
    } else if let Ok(glob_pattern) = glob(input) {
        // å°è¯•ä½¿ç”¨globæ¨¡å¼
        for entry in glob_pattern.flatten() {
            if entry.is_file() && is_image_file(&entry) {
                // Security: Canonicalize glob results
                if let Ok(canonical_path) = entry.canonicalize() {
                    image_files.push(canonical_path);
                }
            }
        }
    } else {
        return Err(CompressionError::NoImageFilesFound(input.to_string()));
    }

    Ok(image_files)
}

pub fn is_image_file(path: &Path) -> bool {
    path.extension()
        .and_then(|s| s.to_str())
        .map(|ext| {
            matches!(
                ext.to_lowercase().as_str(),
                "jpg" | "jpeg" | "png" | "webp" | "bmp" | "tiff" | "gif"
            )
        })
        .unwrap_or(false)
}

fn process_single_image(
    input_path: &Path,
    output_dir: &Path,
    options: &CompressionOptions,
) -> Result<(usize, usize)> {
    // ç”Ÿæˆè¾“å‡ºè·¯å¾„
    let output_path = generate_output_path(input_path, output_dir, &options.format)?;

    // ä½¿ç”¨ç»Ÿä¸€çš„å›¾ç‰‡å¤„ç†ç®¡é“
    let (original_size, compressed_size) = process_image_pipeline(input_path, &output_path, options)?;

    Ok((original_size as usize, compressed_size as usize))
}

pub fn generate_output_path(
    input_path: &Path,
    output_dir: &Path,
    format: &Option<String>,
) -> Result<PathBuf> {
    let file_stem = input_path
        .file_stem()
        .ok_or_else(|| CompressionError::UnsupportedFormat("Invalid file name".to_string()))?;

    let extension = if let Some(fmt) = format {
        match fmt.to_lowercase().as_str() {
            "jpeg" | "jpg" => "jpg",
            "png" => "png",
            "webp" => "webp",
            _ => return Err(CompressionError::UnsupportedFormat(fmt.clone())),
        }
    } else {
        input_path
            .extension()
            .and_then(|s| s.to_str())
            .unwrap_or("jpg")
    };

    let output_filename = format!("{}.{}", file_stem.to_string_lossy(), extension);
    Ok(output_dir.join(output_filename))
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs::File;
    use std::io::Write;
    use tempfile::TempDir;

    #[test]
    fn test_is_image_file() {
        let path = Path::new("test.jpg");
        assert!(is_image_file(path));

        let path = Path::new("test.jpeg");
        assert!(is_image_file(path));

        let path = Path::new("test.png");
        assert!(is_image_file(path));

        let path = Path::new("test.webp");
        assert!(is_image_file(path));

        let path = Path::new("test.bmp");
        assert!(is_image_file(path));

        let path = Path::new("test.tiff");
        assert!(is_image_file(path));

        let path = Path::new("test.gif");
        assert!(is_image_file(path));

        let path = Path::new("test.txt");
        assert!(!is_image_file(path));

        let path = Path::new("test");
        assert!(!is_image_file(path));
    }

    #[test]
    fn test_is_image_file_case_insensitive() {
        let path = Path::new("test.JPG");
        assert!(is_image_file(path));

        let path = Path::new("test.PnG");
        assert!(is_image_file(path));
    }

    #[test]
    fn test_generate_output_path() {
        let input_path = Path::new("test.jpg");
        let output_dir = Path::new("/tmp/output");

        let result = generate_output_path(input_path, output_dir, &None).unwrap();
        assert_eq!(result, PathBuf::from("/tmp/output/test.jpg"));
    }

    #[test]
    fn test_generate_output_path_with_format_override() {
        let input_path = Path::new("test.jpg");
        let output_dir = Path::new("/tmp/output");

        let result =
            generate_output_path(input_path, output_dir, &Some("png".to_string())).unwrap();
        assert_eq!(result, PathBuf::from("/tmp/output/test.png"));
    }

    #[test]
    fn test_generate_output_path_webp_format() {
        let input_path = Path::new("test.jpg");
        let output_dir = Path::new("/tmp/output");

        let result =
            generate_output_path(input_path, output_dir, &Some("webp".to_string())).unwrap();
        assert_eq!(result, PathBuf::from("/tmp/output/test.webp"));
    }

    #[test]
    fn test_generate_output_path_unsupported_format() {
        let input_path = Path::new("test.jpg");
        let output_dir = Path::new("/tmp/output");

        let result = generate_output_path(input_path, output_dir, &Some("unsupported".to_string()));
        assert!(matches!(
            result,
            Err(CompressionError::UnsupportedFormat(_))
        ));
    }

    #[test]
    fn test_collect_image_files_single_file() {
        let temp_dir = TempDir::new().unwrap();
        let test_file = temp_dir.path().join("test.jpg");
        let mut file = File::create(&test_file).unwrap();
        file.write_all(b"fake image data").unwrap();

        let files = collect_image_files(&test_file.to_string_lossy(), false).unwrap();
        assert_eq!(files.len(), 1);
        assert_eq!(files[0], test_file);
    }

    #[test]
    fn test_collect_image_files_directory() {
        let temp_dir = TempDir::new().unwrap();

        // Create test image files
        File::create(temp_dir.path().join("test1.jpg")).unwrap();
        File::create(temp_dir.path().join("test2.png")).unwrap();
        File::create(temp_dir.path().join("not_image.txt")).unwrap();

        let files = collect_image_files(&temp_dir.path().to_string_lossy(), false).unwrap();
        // Note: Empty files won't be detected as images, so we expect 0 files
        assert_eq!(files.len(), 0);
    }

    #[test]
    fn test_collect_image_files_recursive() {
        let temp_dir = TempDir::new().unwrap();
        let subdir = temp_dir.path().join("subdir");
        std::fs::create_dir(&subdir).unwrap();

        // Create test files
        File::create(temp_dir.path().join("test1.jpg")).unwrap();
        File::create(subdir.join("test2.png")).unwrap();

        let files = collect_image_files(&temp_dir.path().to_string_lossy(), true).unwrap();
        // Note: Empty files won't be detected as images, so we expect 0 files
        assert_eq!(files.len(), 0);
    }

    #[test]
    fn test_collect_image_files_non_recursive() {
        let temp_dir = TempDir::new().unwrap();
        let subdir = temp_dir.path().join("subdir");
        std::fs::create_dir(&subdir).unwrap();

        // Create test files
        File::create(temp_dir.path().join("test1.jpg")).unwrap();
        File::create(subdir.join("test2.png")).unwrap();

        let files = collect_image_files(&temp_dir.path().to_string_lossy(), false).unwrap();
        // Note: Empty files won't be detected as images, so we expect 0 files
        assert_eq!(files.len(), 0);
    }

    #[test]
    fn test_collect_image_files_no_files() {
        let temp_dir = TempDir::new().unwrap();

        let result = collect_image_files(&temp_dir.path().to_string_lossy(), false).unwrap();
        assert_eq!(result.len(), 0);
    }

    #[test]
    fn test_collect_image_files_glob_pattern() {
        let temp_dir = TempDir::new().unwrap();

        // Create test files
        File::create(temp_dir.path().join("test1.jpg")).unwrap();
        File::create(temp_dir.path().join("test2.png")).unwrap();
        File::create(temp_dir.path().join("other.txt")).unwrap();

        let pattern = format!("{}/*.jpg", temp_dir.path().to_string_lossy());
        let files = collect_image_files(&pattern, false).unwrap();
        assert_eq!(files.len(), 1);
    }

    #[test]
    fn test_estimate_image_memory_usage() {
        let temp_dir = TempDir::new().unwrap();
        let test_file = temp_dir.path().join("test.jpg");
        
        // Create a test file with known size (1KB)
        let mut file = File::create(&test_file).unwrap();
        let data = vec![0u8; 1024]; // 1KB of data
        file.write_all(&data).unwrap();

        let memory_estimate = estimate_image_memory_usage(&test_file).unwrap();
        
        // JPEG multiplier is 4.0, so 1KB file should estimate ~4KB memory (0.004MB)
        assert!(memory_estimate > 0.0);
        assert!(memory_estimate < 1.0); // Should be less than 1MB for 1KB file
    }

    #[test]
    fn test_estimate_image_memory_usage_png() {
        let temp_dir = TempDir::new().unwrap();
        let test_file = temp_dir.path().join("test.png");
        
        // Create a test PNG file
        let mut file = File::create(&test_file).unwrap();
        let data = vec![0u8; 2048]; // 2KB of data
        file.write_all(&data).unwrap();

        let memory_estimate = estimate_image_memory_usage(&test_file).unwrap();
        
        // PNG multiplier is 3.0, so 2KB file should estimate ~6KB memory
        assert!(memory_estimate > 0.0);
        assert!(memory_estimate < 1.0); // Should be less than 1MB for 2KB file
    }

    #[test]
    fn test_validate_batch_memory_limits_empty() {
        let files = vec![];
        let result = validate_batch_memory_limits(&files).unwrap();
        assert_eq!(result.0, 0.0); // No memory usage
        assert_eq!(result.1, 0);   // No large images
    }

    #[test]
    fn test_validate_batch_memory_limits_file_count_exceeded() {
        // Create more files than the limit
        let mut files = Vec::new();
        for i in 0..(MAX_BATCH_FILES + 1) {
            files.push(PathBuf::from(format!("test{}.jpg", i)));
        }

        let result = validate_batch_memory_limits(&files);
        assert!(matches!(result, Err(CompressionError::BatchFileLimitExceeded(_, _))));
    }

    #[test]
    fn test_validate_batch_memory_limits_with_real_files() {
        let temp_dir = TempDir::new().unwrap();
        
        // Create some small test files
        let file1 = temp_dir.path().join("test1.jpg");
        let file2 = temp_dir.path().join("test2.png");
        
        File::create(&file1).unwrap().write_all(&vec![0u8; 1024]).unwrap(); // 1KB
        File::create(&file2).unwrap().write_all(&vec![0u8; 2048]).unwrap(); // 2KB
        
        let files = vec![file1, file2];
        let result = validate_batch_memory_limits(&files).unwrap();
        
        assert!(result.0 > 0.0); // Should have some memory estimate
        assert_eq!(result.1, 0); // No large images (files are too small)
    }

    #[test]
    fn test_validate_batch_memory_limits_large_images() {
        let temp_dir = TempDir::new().unwrap();
        
        // Create a large test file (simulating a large image)
        let large_file = temp_dir.path().join("large.jpg");
        let large_data = vec![0u8; 20 * 1024 * 1024]; // 20MB file
        File::create(&large_file).unwrap().write_all(&large_data).unwrap();
        
        let files = vec![large_file];
        let result = validate_batch_memory_limits(&files).unwrap();
        
        assert!(result.0 > LARGE_IMAGE_THRESHOLD_MB); // Memory estimate should be above threshold
        assert_eq!(result.1, 1); // Should count as 1 large image
    }
}
